{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Y_abNSdqJ3",
        "outputId": "88224f74-87ba-4577-d083-ccf078f9fef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(1., grad_fn=<PowBackward0>)\n",
            "weight grad: tensor(-2.)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Input\n",
        "x = torch.tensor(1.0)\n",
        "# Actual output\n",
        "y = torch.tensor(2.0)\n",
        "# Weight\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# Forward pass\n",
        "y_hat = w*x\n",
        "# Calculate loss\n",
        "loss = (y_hat-y)**2\n",
        "print('loss:',loss)\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "print('weight grad:',w.grad)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Create a simple dataset\n",
        "# Let's say we have inputs x and corresponding targets y\n",
        "x = torch.tensor([[1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)\n",
        "y = torch.tensor([[2.0], [4.0], [6.0], [8.0]], dtype=torch.float32)\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # One input feature and one output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model = SimpleNet()\n",
        "\n",
        "# Define a loss function (mean squared error)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define an optimizer (Stochastic Gradient Descent)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "4-a2LDnzfnz_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(x)\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = criterion(outputs, y)\n",
        "    print('epoch:',epoch,'loss:',loss)\n",
        "\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQDRd9XQhTfO",
        "outputId": "2c9a689c-766c-41d6-a104-cea789d8f0e3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: tensor(61.3885, grad_fn=<MseLossBackward0>)\n",
            "epoch: 1 loss: tensor(42.5987, grad_fn=<MseLossBackward0>)\n",
            "epoch: 2 loss: tensor(29.5608, grad_fn=<MseLossBackward0>)\n",
            "epoch: 3 loss: tensor(20.5140, grad_fn=<MseLossBackward0>)\n",
            "epoch: 4 loss: tensor(14.2367, grad_fn=<MseLossBackward0>)\n",
            "epoch: 5 loss: tensor(9.8809, grad_fn=<MseLossBackward0>)\n",
            "epoch: 6 loss: tensor(6.8586, grad_fn=<MseLossBackward0>)\n",
            "epoch: 7 loss: tensor(4.7614, grad_fn=<MseLossBackward0>)\n",
            "epoch: 8 loss: tensor(3.3062, grad_fn=<MseLossBackward0>)\n",
            "epoch: 9 loss: tensor(2.2964, grad_fn=<MseLossBackward0>)\n",
            "epoch: 10 loss: tensor(1.5958, grad_fn=<MseLossBackward0>)\n",
            "epoch: 11 loss: tensor(1.1096, grad_fn=<MseLossBackward0>)\n",
            "epoch: 12 loss: tensor(0.7722, grad_fn=<MseLossBackward0>)\n",
            "epoch: 13 loss: tensor(0.5381, grad_fn=<MseLossBackward0>)\n",
            "epoch: 14 loss: tensor(0.3757, grad_fn=<MseLossBackward0>)\n",
            "epoch: 15 loss: tensor(0.2629, grad_fn=<MseLossBackward0>)\n",
            "epoch: 16 loss: tensor(0.1847, grad_fn=<MseLossBackward0>)\n",
            "epoch: 17 loss: tensor(0.1304, grad_fn=<MseLossBackward0>)\n",
            "epoch: 18 loss: tensor(0.0927, grad_fn=<MseLossBackward0>)\n",
            "epoch: 19 loss: tensor(0.0665, grad_fn=<MseLossBackward0>)\n",
            "epoch: 20 loss: tensor(0.0484, grad_fn=<MseLossBackward0>)\n",
            "epoch: 21 loss: tensor(0.0358, grad_fn=<MseLossBackward0>)\n",
            "epoch: 22 loss: tensor(0.0270, grad_fn=<MseLossBackward0>)\n",
            "epoch: 23 loss: tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
            "epoch: 24 loss: tensor(0.0166, grad_fn=<MseLossBackward0>)\n",
            "epoch: 25 loss: tensor(0.0137, grad_fn=<MseLossBackward0>)\n",
            "epoch: 26 loss: tensor(0.0116, grad_fn=<MseLossBackward0>)\n",
            "epoch: 27 loss: tensor(0.0102, grad_fn=<MseLossBackward0>)\n",
            "epoch: 28 loss: tensor(0.0092, grad_fn=<MseLossBackward0>)\n",
            "epoch: 29 loss: tensor(0.0084, grad_fn=<MseLossBackward0>)\n",
            "epoch: 30 loss: tensor(0.0079, grad_fn=<MseLossBackward0>)\n",
            "epoch: 31 loss: tensor(0.0076, grad_fn=<MseLossBackward0>)\n",
            "epoch: 32 loss: tensor(0.0073, grad_fn=<MseLossBackward0>)\n",
            "epoch: 33 loss: tensor(0.0071, grad_fn=<MseLossBackward0>)\n",
            "epoch: 34 loss: tensor(0.0069, grad_fn=<MseLossBackward0>)\n",
            "epoch: 35 loss: tensor(0.0068, grad_fn=<MseLossBackward0>)\n",
            "epoch: 36 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
            "epoch: 37 loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
            "epoch: 38 loss: tensor(0.0066, grad_fn=<MseLossBackward0>)\n",
            "epoch: 39 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
            "epoch: 40 loss: tensor(0.0065, grad_fn=<MseLossBackward0>)\n",
            "epoch: 41 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
            "epoch: 42 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
            "epoch: 43 loss: tensor(0.0064, grad_fn=<MseLossBackward0>)\n",
            "epoch: 44 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
            "epoch: 45 loss: tensor(0.0063, grad_fn=<MseLossBackward0>)\n",
            "epoch: 46 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
            "epoch: 47 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
            "epoch: 48 loss: tensor(0.0062, grad_fn=<MseLossBackward0>)\n",
            "epoch: 49 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
            "epoch: 50 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
            "epoch: 51 loss: tensor(0.0061, grad_fn=<MseLossBackward0>)\n",
            "epoch: 52 loss: tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
            "epoch: 53 loss: tensor(0.0060, grad_fn=<MseLossBackward0>)\n",
            "epoch: 54 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
            "epoch: 55 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
            "epoch: 56 loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
            "epoch: 57 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
            "epoch: 58 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
            "epoch: 59 loss: tensor(0.0058, grad_fn=<MseLossBackward0>)\n",
            "epoch: 60 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
            "epoch: 61 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
            "epoch: 62 loss: tensor(0.0057, grad_fn=<MseLossBackward0>)\n",
            "epoch: 63 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
            "epoch: 64 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
            "epoch: 65 loss: tensor(0.0056, grad_fn=<MseLossBackward0>)\n",
            "epoch: 66 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
            "epoch: 67 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
            "epoch: 68 loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
            "epoch: 69 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
            "epoch: 70 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
            "epoch: 71 loss: tensor(0.0054, grad_fn=<MseLossBackward0>)\n",
            "epoch: 72 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
            "epoch: 73 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
            "epoch: 74 loss: tensor(0.0053, grad_fn=<MseLossBackward0>)\n",
            "epoch: 75 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
            "epoch: 76 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
            "epoch: 77 loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
            "epoch: 78 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
            "epoch: 79 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
            "epoch: 80 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
            "epoch: 81 loss: tensor(0.0051, grad_fn=<MseLossBackward0>)\n",
            "epoch: 82 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
            "epoch: 83 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
            "epoch: 84 loss: tensor(0.0050, grad_fn=<MseLossBackward0>)\n",
            "epoch: 85 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
            "epoch: 86 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
            "epoch: 87 loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
            "epoch: 88 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
            "epoch: 89 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
            "epoch: 90 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
            "epoch: 91 loss: tensor(0.0048, grad_fn=<MseLossBackward0>)\n",
            "epoch: 92 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
            "epoch: 93 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
            "epoch: 94 loss: tensor(0.0047, grad_fn=<MseLossBackward0>)\n",
            "epoch: 95 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
            "epoch: 96 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
            "epoch: 97 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
            "epoch: 98 loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
            "epoch: 99 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
            "Epoch [100/1000], Loss: 0.0045\n",
            "epoch: 100 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
            "epoch: 101 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
            "epoch: 102 loss: tensor(0.0045, grad_fn=<MseLossBackward0>)\n",
            "epoch: 103 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
            "epoch: 104 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
            "epoch: 105 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
            "epoch: 106 loss: tensor(0.0044, grad_fn=<MseLossBackward0>)\n",
            "epoch: 107 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
            "epoch: 108 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
            "epoch: 109 loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n",
            "epoch: 110 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
            "epoch: 111 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
            "epoch: 112 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
            "epoch: 113 loss: tensor(0.0042, grad_fn=<MseLossBackward0>)\n",
            "epoch: 114 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
            "epoch: 115 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
            "epoch: 116 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
            "epoch: 117 loss: tensor(0.0041, grad_fn=<MseLossBackward0>)\n",
            "epoch: 118 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
            "epoch: 119 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
            "epoch: 120 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
            "epoch: 121 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
            "epoch: 122 loss: tensor(0.0040, grad_fn=<MseLossBackward0>)\n",
            "epoch: 123 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
            "epoch: 124 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
            "epoch: 125 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
            "epoch: 126 loss: tensor(0.0039, grad_fn=<MseLossBackward0>)\n",
            "epoch: 127 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
            "epoch: 128 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
            "epoch: 129 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
            "epoch: 130 loss: tensor(0.0038, grad_fn=<MseLossBackward0>)\n",
            "epoch: 131 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
            "epoch: 132 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
            "epoch: 133 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
            "epoch: 134 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
            "epoch: 135 loss: tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
            "epoch: 136 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
            "epoch: 137 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
            "epoch: 138 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
            "epoch: 139 loss: tensor(0.0036, grad_fn=<MseLossBackward0>)\n",
            "epoch: 140 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
            "epoch: 141 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
            "epoch: 142 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
            "epoch: 143 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
            "epoch: 144 loss: tensor(0.0035, grad_fn=<MseLossBackward0>)\n",
            "epoch: 145 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
            "epoch: 146 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
            "epoch: 147 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
            "epoch: 148 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
            "epoch: 149 loss: tensor(0.0034, grad_fn=<MseLossBackward0>)\n",
            "epoch: 150 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
            "epoch: 151 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
            "epoch: 152 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
            "epoch: 153 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
            "epoch: 154 loss: tensor(0.0033, grad_fn=<MseLossBackward0>)\n",
            "epoch: 155 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
            "epoch: 156 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
            "epoch: 157 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
            "epoch: 158 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
            "epoch: 159 loss: tensor(0.0032, grad_fn=<MseLossBackward0>)\n",
            "epoch: 160 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
            "epoch: 161 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
            "epoch: 162 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
            "epoch: 163 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
            "epoch: 164 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
            "epoch: 165 loss: tensor(0.0031, grad_fn=<MseLossBackward0>)\n",
            "epoch: 166 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
            "epoch: 167 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
            "epoch: 168 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
            "epoch: 169 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
            "epoch: 170 loss: tensor(0.0030, grad_fn=<MseLossBackward0>)\n",
            "epoch: 171 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
            "epoch: 172 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
            "epoch: 173 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
            "epoch: 174 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
            "epoch: 175 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
            "epoch: 176 loss: tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
            "epoch: 177 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
            "epoch: 178 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
            "epoch: 179 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
            "epoch: 180 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
            "epoch: 181 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
            "epoch: 182 loss: tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
            "epoch: 183 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
            "epoch: 184 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
            "epoch: 185 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
            "epoch: 186 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
            "epoch: 187 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
            "epoch: 188 loss: tensor(0.0027, grad_fn=<MseLossBackward0>)\n",
            "epoch: 189 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
            "epoch: 190 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
            "epoch: 191 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
            "epoch: 192 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
            "epoch: 193 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
            "epoch: 194 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
            "epoch: 195 loss: tensor(0.0026, grad_fn=<MseLossBackward0>)\n",
            "epoch: 196 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
            "epoch: 197 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
            "epoch: 198 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
            "epoch: 199 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
            "Epoch [200/1000], Loss: 0.0025\n",
            "epoch: 200 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
            "epoch: 201 loss: tensor(0.0025, grad_fn=<MseLossBackward0>)\n",
            "epoch: 202 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
            "epoch: 203 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
            "epoch: 204 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
            "epoch: 205 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
            "epoch: 206 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
            "epoch: 207 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
            "epoch: 208 loss: tensor(0.0024, grad_fn=<MseLossBackward0>)\n",
            "epoch: 209 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "epoch: 210 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "epoch: 211 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "epoch: 212 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "epoch: 213 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "epoch: 214 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "epoch: 215 loss: tensor(0.0023, grad_fn=<MseLossBackward0>)\n",
            "epoch: 216 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch: 217 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch: 218 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch: 219 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch: 220 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch: 221 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch: 222 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch: 223 loss: tensor(0.0022, grad_fn=<MseLossBackward0>)\n",
            "epoch: 224 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
            "epoch: 225 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
            "epoch: 226 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
            "epoch: 227 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
            "epoch: 228 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
            "epoch: 229 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
            "epoch: 230 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
            "epoch: 231 loss: tensor(0.0021, grad_fn=<MseLossBackward0>)\n",
            "epoch: 232 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "epoch: 233 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "epoch: 234 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "epoch: 235 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "epoch: 236 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "epoch: 237 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "epoch: 238 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "epoch: 239 loss: tensor(0.0020, grad_fn=<MseLossBackward0>)\n",
            "epoch: 240 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 241 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 242 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 243 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 244 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 245 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 246 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 247 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 248 loss: tensor(0.0019, grad_fn=<MseLossBackward0>)\n",
            "epoch: 249 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 250 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 251 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 252 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 253 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 254 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 255 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 256 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 257 loss: tensor(0.0018, grad_fn=<MseLossBackward0>)\n",
            "epoch: 258 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 259 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 260 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 261 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 262 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 263 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 264 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 265 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 266 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 267 loss: tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch: 268 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 269 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 270 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 271 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 272 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 273 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 274 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 275 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 276 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 277 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 278 loss: tensor(0.0016, grad_fn=<MseLossBackward0>)\n",
            "epoch: 279 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 280 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 281 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 282 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 283 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 284 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 285 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 286 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 287 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 288 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 289 loss: tensor(0.0015, grad_fn=<MseLossBackward0>)\n",
            "epoch: 290 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 291 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 292 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 293 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 294 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 295 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 296 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 297 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 298 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 299 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "Epoch [300/1000], Loss: 0.0014\n",
            "epoch: 300 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 301 loss: tensor(0.0014, grad_fn=<MseLossBackward0>)\n",
            "epoch: 302 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 303 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 304 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 305 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 306 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 307 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 308 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 309 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 310 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 311 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 312 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 313 loss: tensor(0.0013, grad_fn=<MseLossBackward0>)\n",
            "epoch: 314 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 315 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 316 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 317 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 318 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 319 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 320 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 321 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 322 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 323 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 324 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 325 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 326 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 327 loss: tensor(0.0012, grad_fn=<MseLossBackward0>)\n",
            "epoch: 328 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 329 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 330 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 331 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 332 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 333 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 334 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 335 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 336 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 337 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 338 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 339 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 340 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 341 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 342 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 343 loss: tensor(0.0011, grad_fn=<MseLossBackward0>)\n",
            "epoch: 344 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 345 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 346 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 347 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 348 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 349 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 350 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 351 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 352 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 353 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 354 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 355 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 356 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 357 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 358 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 359 loss: tensor(0.0010, grad_fn=<MseLossBackward0>)\n",
            "epoch: 360 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 361 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 362 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 363 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 364 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 365 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 366 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 367 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 368 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 369 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 370 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 371 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 372 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 373 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 374 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 375 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 376 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 377 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 378 loss: tensor(0.0009, grad_fn=<MseLossBackward0>)\n",
            "epoch: 379 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 380 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 381 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 382 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 383 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 384 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 385 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 386 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 387 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 388 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 389 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 390 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 391 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 392 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 393 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 394 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 395 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 396 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 397 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 398 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "epoch: 399 loss: tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
            "Epoch [400/1000], Loss: 0.0008\n",
            "epoch: 400 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 401 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 402 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 403 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 404 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 405 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 406 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 407 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 408 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 409 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 410 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 411 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 412 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 413 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 414 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 415 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 416 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 417 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 418 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 419 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 420 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 421 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 422 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 423 loss: tensor(0.0007, grad_fn=<MseLossBackward0>)\n",
            "epoch: 424 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 425 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 426 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 427 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 428 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 429 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 430 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 431 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 432 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 433 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 434 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 435 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 436 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 437 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 438 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 439 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 440 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 441 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 442 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 443 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 444 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 445 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 446 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 447 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 448 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 449 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 450 loss: tensor(0.0006, grad_fn=<MseLossBackward0>)\n",
            "epoch: 451 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 452 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 453 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 454 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 455 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 456 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 457 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 458 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 459 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 460 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 461 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 462 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 463 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 464 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 465 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 466 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 467 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 468 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 469 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 470 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 471 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 472 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 473 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 474 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 475 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 476 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 477 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 478 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 479 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 480 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 481 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 482 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 483 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 484 loss: tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
            "epoch: 485 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 486 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 487 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 488 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 489 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 490 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 491 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 492 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 493 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 494 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 495 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 496 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 497 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 498 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 499 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "Epoch [500/1000], Loss: 0.0004\n",
            "epoch: 500 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 501 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 502 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 503 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 504 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 505 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 506 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 507 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 508 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 509 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 510 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 511 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 512 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 513 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 514 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 515 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 516 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 517 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 518 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 519 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 520 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 521 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 522 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 523 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 524 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 525 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 526 loss: tensor(0.0004, grad_fn=<MseLossBackward0>)\n",
            "epoch: 527 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 528 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 529 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 530 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 531 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 532 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 533 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 534 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 535 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 536 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 537 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 538 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 539 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 540 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 541 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 542 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 543 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 544 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 545 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 546 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 547 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 548 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 549 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 550 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 551 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 552 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 553 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 554 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 555 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 556 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 557 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 558 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 559 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 560 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 561 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 562 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 563 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 564 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 565 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 566 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 567 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 568 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 569 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 570 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 571 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 572 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 573 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 574 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 575 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 576 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 577 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 578 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 579 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 580 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 581 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 582 loss: tensor(0.0003, grad_fn=<MseLossBackward0>)\n",
            "epoch: 583 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 584 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 585 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 586 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 587 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 588 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 589 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 590 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 591 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 592 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 593 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 594 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 595 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 596 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 597 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 598 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 599 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "Epoch [600/1000], Loss: 0.0002\n",
            "epoch: 600 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 601 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 602 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 603 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 604 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 605 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 606 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 607 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 608 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 609 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 610 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 611 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 612 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 613 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 614 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 615 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 616 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 617 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 618 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 619 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 620 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 621 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 622 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 623 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 624 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 625 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 626 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 627 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 628 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 629 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 630 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 631 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 632 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 633 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 634 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 635 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 636 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 637 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 638 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 639 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 640 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 641 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 642 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 643 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 644 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 645 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 646 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 647 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 648 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 649 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 650 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 651 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 652 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 653 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 654 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 655 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 656 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 657 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 658 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 659 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 660 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 661 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 662 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 663 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 664 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 665 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 666 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 667 loss: tensor(0.0002, grad_fn=<MseLossBackward0>)\n",
            "epoch: 668 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 669 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 670 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 671 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 672 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 673 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 674 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 675 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 676 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 677 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 678 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 679 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 680 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 681 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 682 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 683 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 684 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 685 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 686 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 687 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 688 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 689 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 690 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 691 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 692 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 693 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 694 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 695 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 696 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 697 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 698 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 699 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "Epoch [700/1000], Loss: 0.0001\n",
            "epoch: 700 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 701 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 702 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 703 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 704 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 705 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 706 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 707 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 708 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 709 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 710 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 711 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 712 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 713 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 714 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 715 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 716 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 717 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 718 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 719 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 720 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 721 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 722 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 723 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 724 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 725 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 726 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 727 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 728 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 729 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 730 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 731 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 732 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 733 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 734 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 735 loss: tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
            "epoch: 736 loss: tensor(9.9504e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 737 loss: tensor(9.8908e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 738 loss: tensor(9.8320e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 739 loss: tensor(9.7730e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 740 loss: tensor(9.7145e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 741 loss: tensor(9.6566e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 742 loss: tensor(9.5988e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 743 loss: tensor(9.5412e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 744 loss: tensor(9.4842e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 745 loss: tensor(9.4276e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 746 loss: tensor(9.3711e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 747 loss: tensor(9.3154e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 748 loss: tensor(9.2594e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 749 loss: tensor(9.2042e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 750 loss: tensor(9.1491e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 751 loss: tensor(9.0943e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 752 loss: tensor(9.0400e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 753 loss: tensor(8.9862e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 754 loss: tensor(8.9323e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 755 loss: tensor(8.8790e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 756 loss: tensor(8.8258e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 757 loss: tensor(8.7732e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 758 loss: tensor(8.7207e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 759 loss: tensor(8.6685e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 760 loss: tensor(8.6165e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 761 loss: tensor(8.5652e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 762 loss: tensor(8.5141e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 763 loss: tensor(8.4631e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 764 loss: tensor(8.4124e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 765 loss: tensor(8.3621e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 766 loss: tensor(8.3121e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 767 loss: tensor(8.2625e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 768 loss: tensor(8.2129e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 769 loss: tensor(8.1639e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 770 loss: tensor(8.1150e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 771 loss: tensor(8.0667e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 772 loss: tensor(8.0184e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 773 loss: tensor(7.9705e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 774 loss: tensor(7.9227e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 775 loss: tensor(7.8753e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 776 loss: tensor(7.8283e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 777 loss: tensor(7.7815e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 778 loss: tensor(7.7350e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 779 loss: tensor(7.6888e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 780 loss: tensor(7.6429e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 781 loss: tensor(7.5971e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 782 loss: tensor(7.5516e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 783 loss: tensor(7.5065e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 784 loss: tensor(7.4616e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 785 loss: tensor(7.4170e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 786 loss: tensor(7.3727e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 787 loss: tensor(7.3286e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 788 loss: tensor(7.2848e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 789 loss: tensor(7.2413e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 790 loss: tensor(7.1979e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 791 loss: tensor(7.1548e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 792 loss: tensor(7.1122e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 793 loss: tensor(7.0697e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 794 loss: tensor(7.0273e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 795 loss: tensor(6.9854e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 796 loss: tensor(6.9436e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 797 loss: tensor(6.9021e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 798 loss: tensor(6.8609e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 799 loss: tensor(6.8199e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch [800/1000], Loss: 0.0001\n",
            "epoch: 800 loss: tensor(6.7790e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 801 loss: tensor(6.7384e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 802 loss: tensor(6.6982e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 803 loss: tensor(6.6582e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 804 loss: tensor(6.6184e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 805 loss: tensor(6.5788e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 806 loss: tensor(6.5393e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 807 loss: tensor(6.5003e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 808 loss: tensor(6.4615e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 809 loss: tensor(6.4228e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 810 loss: tensor(6.3844e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 811 loss: tensor(6.3463e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 812 loss: tensor(6.3083e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 813 loss: tensor(6.2706e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 814 loss: tensor(6.2332e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 815 loss: tensor(6.1959e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 816 loss: tensor(6.1589e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 817 loss: tensor(6.1220e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 818 loss: tensor(6.0854e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 819 loss: tensor(6.0490e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 820 loss: tensor(6.0127e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 821 loss: tensor(5.9768e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 822 loss: tensor(5.9411e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 823 loss: tensor(5.9056e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 824 loss: tensor(5.8703e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 825 loss: tensor(5.8351e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 826 loss: tensor(5.8003e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 827 loss: tensor(5.7657e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 828 loss: tensor(5.7311e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 829 loss: tensor(5.6969e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 830 loss: tensor(5.6628e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 831 loss: tensor(5.6290e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 832 loss: tensor(5.5953e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 833 loss: tensor(5.5618e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 834 loss: tensor(5.5287e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 835 loss: tensor(5.4956e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 836 loss: tensor(5.4626e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 837 loss: tensor(5.4301e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 838 loss: tensor(5.3975e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 839 loss: tensor(5.3654e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 840 loss: tensor(5.3331e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 841 loss: tensor(5.3013e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 842 loss: tensor(5.2696e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 843 loss: tensor(5.2381e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 844 loss: tensor(5.2067e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 845 loss: tensor(5.1756e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 846 loss: tensor(5.1447e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 847 loss: tensor(5.1140e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 848 loss: tensor(5.0834e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 849 loss: tensor(5.0530e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 850 loss: tensor(5.0227e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 851 loss: tensor(4.9927e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 852 loss: tensor(4.9630e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 853 loss: tensor(4.9332e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 854 loss: tensor(4.9038e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 855 loss: tensor(4.8744e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 856 loss: tensor(4.8453e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 857 loss: tensor(4.8163e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 858 loss: tensor(4.7874e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 859 loss: tensor(4.7589e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 860 loss: tensor(4.7305e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 861 loss: tensor(4.7021e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 862 loss: tensor(4.6741e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 863 loss: tensor(4.6461e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 864 loss: tensor(4.6183e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 865 loss: tensor(4.5908e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 866 loss: tensor(4.5633e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 867 loss: tensor(4.5360e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 868 loss: tensor(4.5087e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 869 loss: tensor(4.4818e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 870 loss: tensor(4.4550e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 871 loss: tensor(4.4285e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 872 loss: tensor(4.4021e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 873 loss: tensor(4.3756e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 874 loss: tensor(4.3495e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 875 loss: tensor(4.3235e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 876 loss: tensor(4.2976e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 877 loss: tensor(4.2720e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 878 loss: tensor(4.2464e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 879 loss: tensor(4.2210e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 880 loss: tensor(4.1957e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 881 loss: tensor(4.1707e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 882 loss: tensor(4.1458e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 883 loss: tensor(4.1210e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 884 loss: tensor(4.0962e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 885 loss: tensor(4.0718e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 886 loss: tensor(4.0475e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 887 loss: tensor(4.0232e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 888 loss: tensor(3.9993e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 889 loss: tensor(3.9754e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 890 loss: tensor(3.9516e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 891 loss: tensor(3.9279e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 892 loss: tensor(3.9045e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 893 loss: tensor(3.8812e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 894 loss: tensor(3.8579e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 895 loss: tensor(3.8348e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 896 loss: tensor(3.8119e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 897 loss: tensor(3.7892e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 898 loss: tensor(3.7664e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 899 loss: tensor(3.7440e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch [900/1000], Loss: 0.0000\n",
            "epoch: 900 loss: tensor(3.7216e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 901 loss: tensor(3.6993e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 902 loss: tensor(3.6772e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 903 loss: tensor(3.6551e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 904 loss: tensor(3.6334e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 905 loss: tensor(3.6116e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 906 loss: tensor(3.5901e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 907 loss: tensor(3.5686e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 908 loss: tensor(3.5473e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 909 loss: tensor(3.5261e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 910 loss: tensor(3.5049e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 911 loss: tensor(3.4839e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 912 loss: tensor(3.4631e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 913 loss: tensor(3.4425e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 914 loss: tensor(3.4219e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 915 loss: tensor(3.4014e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 916 loss: tensor(3.3810e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 917 loss: tensor(3.3608e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 918 loss: tensor(3.3408e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 919 loss: tensor(3.3207e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 920 loss: tensor(3.3009e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 921 loss: tensor(3.2812e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 922 loss: tensor(3.2616e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 923 loss: tensor(3.2422e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 924 loss: tensor(3.2227e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 925 loss: tensor(3.2035e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 926 loss: tensor(3.1843e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 927 loss: tensor(3.1652e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 928 loss: tensor(3.1464e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 929 loss: tensor(3.1275e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 930 loss: tensor(3.1089e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 931 loss: tensor(3.0902e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 932 loss: tensor(3.0717e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 933 loss: tensor(3.0534e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 934 loss: tensor(3.0351e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 935 loss: tensor(3.0170e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 936 loss: tensor(2.9989e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 937 loss: tensor(2.9810e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 938 loss: tensor(2.9632e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 939 loss: tensor(2.9455e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 940 loss: tensor(2.9278e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 941 loss: tensor(2.9102e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 942 loss: tensor(2.8929e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 943 loss: tensor(2.8757e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 944 loss: tensor(2.8584e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 945 loss: tensor(2.8414e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 946 loss: tensor(2.8243e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 947 loss: tensor(2.8075e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 948 loss: tensor(2.7906e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 949 loss: tensor(2.7740e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 950 loss: tensor(2.7574e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 951 loss: tensor(2.7410e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 952 loss: tensor(2.7245e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 953 loss: tensor(2.7083e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 954 loss: tensor(2.6921e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 955 loss: tensor(2.6760e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 956 loss: tensor(2.6600e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 957 loss: tensor(2.6441e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 958 loss: tensor(2.6282e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 959 loss: tensor(2.6126e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 960 loss: tensor(2.5970e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 961 loss: tensor(2.5814e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 962 loss: tensor(2.5660e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 963 loss: tensor(2.5506e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 964 loss: tensor(2.5354e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 965 loss: tensor(2.5202e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 966 loss: tensor(2.5051e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 967 loss: tensor(2.4901e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 968 loss: tensor(2.4754e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 969 loss: tensor(2.4605e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 970 loss: tensor(2.4458e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 971 loss: tensor(2.4312e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 972 loss: tensor(2.4166e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 973 loss: tensor(2.4022e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 974 loss: tensor(2.3877e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 975 loss: tensor(2.3735e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 976 loss: tensor(2.3593e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 977 loss: tensor(2.3453e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 978 loss: tensor(2.3311e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 979 loss: tensor(2.3173e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 980 loss: tensor(2.3034e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 981 loss: tensor(2.2897e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 982 loss: tensor(2.2760e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 983 loss: tensor(2.2624e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 984 loss: tensor(2.2488e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 985 loss: tensor(2.2354e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 986 loss: tensor(2.2220e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 987 loss: tensor(2.2088e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 988 loss: tensor(2.1955e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 989 loss: tensor(2.1824e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 990 loss: tensor(2.1694e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 991 loss: tensor(2.1564e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 992 loss: tensor(2.1435e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 993 loss: tensor(2.1307e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 994 loss: tensor(2.1180e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 995 loss: tensor(2.1053e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 996 loss: tensor(2.0927e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 997 loss: tensor(2.0802e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 998 loss: tensor(2.0677e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch: 999 loss: tensor(2.0554e-05, grad_fn=<MseLossBackward0>)\n",
            "Epoch [1000/1000], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the trained model\n",
        "test_input = torch.tensor([[5.0]], dtype=torch.float32)\n",
        "predicted_output = model(test_input)\n",
        "print(f'Predicted output for input {test_input.item():.1f}: {predicted_output.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwSFVhb2ho-2",
        "outputId": "8ac8687d-4109-4f44-f38f-d73d6008affa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted output for input 5.0: 9.9923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the updated model parameters\n",
        "print(\"Updated model parameters:\")\n",
        "for name, param in model.state_dict().items():\n",
        "    print(name, param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3d3_52Ujc3G",
        "outputId": "a66ee587-e738-4027-8ddc-8e7ae7f5b262"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated model parameters:\n",
            "linear.weight tensor([[1.9962]])\n",
            "linear.bias tensor([0.0111])\n"
          ]
        }
      ]
    }
  ]
}